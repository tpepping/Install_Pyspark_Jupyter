{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Spark: Lightning-fast data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"README.md\")\n",
    "lines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'# Apache Spark'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3 Programming with RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pythonLines = lines.filter(lambda line: \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythonLines.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persist() is used to load a subset of your data into memory and query it repeatedly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythonLines.persist\n",
    "pythonLines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating RDDs\n",
    "- Transformations: \n",
    "            - operations on RDDs that return a new RDD\n",
    "            - transformations are lazily evaluated, meaning Spark will not begin to execute until it sees an action. \n",
    "- Actions: operations that return a final value to the driver program or write data to an external storage system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.parallelize([\"pandas\", \"i like pandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputRDD = sc.textFile(\"log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errorsRDD = inputRDD.filter(lambda x: \"Praesent\" in x)\n",
    "warningsRDD = inputRDD.filter(lambda x: \"sapien\" in x)\n",
    "badLinesRDD = errorsRDD.union(warningsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badLinesRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nam pretium turpis et arcu. Duis arcu tortor, suscipit eget, imperdiet nec, imperdiet iaculis, ipsum. Sed aliquam ultrices mauris. Integer ante arcu, accumsan a, consectetuer eget, posuere ut, mauris. Praesent adipiscing. Phasellus ullamcorper ipsum rutrum nunc. Nunc nonummy metus. Vestibulum volutpat pretium libero. Cras id dui. Aenean ut eros et nisl sagittis vestibulum. Nullam nulla eros, ultricies sit amet, nonummy id, imperdiet feugiat, pede. Sed lectus. Donec mollis hendrerit risus. Phasellus nec sem in justo pellentesque facilisis. Etiam imperdiet imperdiet orci. Nunc nec neque. Phasellus leo dolor, tempus non, auctor et, hendrerit quis, nisi.\n"
     ]
    }
   ],
   "source": [
    "##print \"Input had \" + badLinesRDD.count() + \" concerning lines\"\n",
    "##print \"Here are 10 examples:\"\n",
    "# voorbeeld uit het boek, selecteer de eerste regel\n",
    "for line in badLinesRDD.take(1):\n",
    "    print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "4 \n",
      "9 \n",
      "9 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a RDD \n",
    "nums = sc.parallelize([1,2,3,3])\n",
    "# squaring the values in an RDD\n",
    "squared = nums.map(lambda x: x * x).collect()\n",
    "for k in squared:\n",
    "    print \"%i \" % (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatMap() in Python, splitting lines into words\n",
    "lines = sc.parallelize([\"hello world\", \"hi\"])\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "words.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "3 \n",
      "4 \n",
      "4 \n"
     ]
    }
   ],
   "source": [
    "# Basic transformations on page 38\n",
    "# first make RDD to work with\n",
    "cijfers = sc.parallelize([1,2,3,3])\n",
    "# map() - apply a function to each element in the RDD and return n RDD of the result\n",
    "test = cijfers.map(lambda x: x + 1).collect()\n",
    "for k in test:\n",
    "    print \"%i \" % (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woord'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatMap() - apply a function to each element in the RDD and return an RDD of the contents of the iterators returned.\n",
    "# Often used to extract words \n",
    "woorden = sc.parallelize([\"woord\", \"het\" \"is vrijdag\"])\n",
    "woord = woorden.flatMap(lambda x: x.split(\" \"))\n",
    "woord.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter() - return an RDD consisting of only elements that pass the condition passed to filter()\n",
    "f = cijfers.filter(lambda x: x != 1)\n",
    "f.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "2 \n",
      "3 \n"
     ]
    }
   ],
   "source": [
    "# distinct() - remove duplicates\n",
    "cijfer = sc.parallelize([1,2,3,3])\n",
    "d = cijfer.distinct().collect()\n",
    "for k in d:\n",
    "    print \"%i \" % (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# sample(withReplacement, fraction, [seed]) \n",
    "# wat doet deze ?? \n",
    "t = cijfer.sample(2, 0.5).collect()\n",
    "for k in t:\n",
    "    print (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# union(), intersection(), subtract(), cartesian()\n",
    "t1 = sc.parallelize([1,2,3])\n",
    "t2 = sc.parallelize([3,4,5])\n",
    "t3 = t1.union(t2).collect()\n",
    "for k in t3:\n",
    "    print (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic actions on a RDD \n",
    "# collect(), count(), countByValue()\n",
    "v = sc.parallelize([1,2,4,4])\n",
    "v.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 1, 4: 2})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take(num), top(num), TakeOrdered(num)(ordering), takeSample(withReplacement, num, [seed]), reduce(func), fold(zero)(func)\n",
    "# aggregate(zeroValue)(seqOp, combOp), foreach(func)\n",
    "v = sc.parallelize([1,2,4,5])\n",
    "v.take(2)\n",
    "v.top(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4 Working with Key/Value Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Key/value RDDs are commonly used to perform aggregations. \n",
    "- Partitioning: lets users control the layout of pair RDDs across nodes\n",
    "- ! Choosing the right partitioning for a distributed dataset is similar to choosing the right data structure for a local one- in both case, data layout can greatly affect performance. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
